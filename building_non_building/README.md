
# Building, Non-Building Classification

![GitHub](https://raw.githubusercontent.com/geoaihub/geoaihub/main/assets/Mersin%20GeoAI%20Hub%203.png)

Picture Source: [GeoAI Hub Mersin](https://github.com/geoaihub)

## Abstract

This research presents an automated approach for detecting and classifying in high-resolution satellite images, particularly in the aftermath of the Hatay earthquake, utilizing Maxar high-resolution satellite imagery. Advanced deep learning models are employed to identify "building" and "non-building" building classes.

### Architectures

- [ResNet-50](https://github.com/geoaihub/GeoAdvances-EQ-Scene-Classification-2023-Kahramanmaras/blob/main/building_non_building/build_nonbuild_ResNet50.ipynb)
- [ResNet-50V2](https://github.com/geoaihub/GeoAdvances-EQ-Scene-Classification-2023-Kahramanmaras/blob/main/building_non_building/build_nonbuild_ResNet50V2.ipynb)
- [ResNet-101](https://github.com/geoaihub/GeoAdvances-EQ-Scene-Classification-2023-Kahramanmaras/blob/main/building_non_building/build_nonbuild_ResNet101.ipynb)
- [VGG-16](https://github.com/geoaihub/GeoAdvances-EQ-Scene-Classification-2023-Kahramanmaras/blob/main/building_non_building/build_nonbuild_VGG16.ipynb)
- [VGG-19](https://github.com/geoaihub/GeoAdvances-EQ-Scene-Classification-2023-Kahramanmaras/blob/main/building_non_building/build_nonbuild_VGG19.ipynb)
- [DenseNet-169](https://github.com/geoaihub/GeoAdvances-EQ-Scene-Classification-2023-Kahramanmaras/blob/main/building_non_building/build_nonbuild_DenseNet169.ipynb)
- [DenseNet-121](https://github.com/geoaihub/GeoAdvances-EQ-Scene-Classification-2023-Kahramanmaras/blob/main/building_non_building/build_nonbuild_DenseNet121.ipynb)
- [MobileNetV2](https://github.com/geoaihub/GeoAdvances-EQ-Scene-Classification-2023-Kahramanmaras/blob/main/building_non_building/build_nonbuild_MobileNetV2.ipynb)

## ResNet-50

### Abstract

Our ResNet-50 model, meticulously tailored for building and non-building scene classification, has demonstrated outstanding performance across a range of pivotal metrics. During the training process, the model achieved a commendably low loss value of 0.1997, underlining its strong predictive capabilities. Furthermore, the model exhibited exceptional accuracy, precision, and recall, all reaching a noteworthy 93.33%. These metrics emphasize the model's remarkable proficiency in accurately distinguishing between building and non-building scenes.

The F1 score, a critical metric that harmonizes precision and recall, reached an impressive value of 0.93, signifying the model's ability to effectively manage both true positives and true negatives.

The model's utilization of the softmax activation function and categorical cross-entropy loss function, in conjunction with 32 training epochs, has proven to be a highly effective approach in refining this ResNet-50 model. These results collectively underscore the model's significant potential in scene classification tasks, with versatile applications spanning remote sensing, environmental monitoring, and beyond.

## ResNet-50V2

### Abstract

Our ResNet-50V2 model, meticulously crafted for building and non-building scene classification, has demonstrated exceptional performance across an array of critical metrics. Throughout the training process, the model achieved a notably low loss value of 0.1731, signifying its robust predictive capabilities. Furthermore, the model showcased remarkable accuracy, precision, and recall, all attaining an impressive 95.83%. These metrics highlight the model's commendable proficiency in accurately distinguishing between building and non-building scenes.

The F1 score, a pivotal metric that harmonizes precision and recall, reached an outstanding value of 0.96, underscoring the model's capability to effectively manage both true positives and true negatives.  

The model's utilization of the softmax activation function and categorical cross-entropy loss function, along with 32 training epochs, has proven to be a highly effective strategy in refining this ResNet-50V2 model. These results collectively emphasize the model's significant potential in scene classification tasks, with wide-ranging applications spanning remote sensing, environmental monitoring, and beyond.

## ResNet-101

### Abstract

Our ResNet-101 model, meticulously tailored for building and non-building scene classification, has showcased extraordinary performance across essential metrics. During training, the model achieved an exceptionally low loss value of 0.1514, highlighting its robust predictive capabilities. Additionally, the model demonstrated exceptional accuracy, precision, and recall, all reaching an impressive 99.17%. These metrics underscore the model's exceptional proficiency in accurately distinguishing between building and non-building scenes.

The F1 score, a pivotal metric that harmonizes precision and recall, reached a remarkable value of 0.99, signifying the model's exceptional ability to effectively manage both true positives and true negatives.

With the softmax activation function and categorical cross-entropy loss function, combined with 32 training epochs, this ResNet-101 model has proven to be an invaluable asset in scene classification tasks. These outstanding results emphasize the model's substantial potential in remote sensing, environmental monitoring, and a wide array of other applications.

## VGG-16

### Abstract

Our VGG-16 model, designed for building and non-building scene classification, has delivered impressive performance across various key metrics. During training, the model achieved a low loss value of 0.3142, highlighting its strong predictive capabilities. The model also demonstrated high levels of accuracy, precision, and recall, all registering at 87.50%. This showcases its remarkable ability to accurately distinguish between building and non-building scenes.

Additionally, the F1 score, which harmonizes precision and recall, reached an impressive value of 0.88, underlining the model's balanced performance in handling both true positives and true negatives.

The use of the softmax activation function and categorical cross-entropy loss function has proven effective in training this model over 32 epochs. These results collectively emphasize the model's potential in scene classification tasks, with applications spanning from remote sensing to environmental monitoring and beyond.

## VGG-19

### Abstract

Our VGG-19 model, engineered for building and non-building scene classification, has exhibited exceptional performance across various vital metrics. During training, the model achieved a notably low loss value of 0.2851, signifying its robust predictive capabilities. Moreover, the model demonstrated outstanding accuracy, precision, and recall, all registering at an impressive 88.33%. This underscores its remarkable capacity to accurately differentiate between building and non-building scenes.

The F1 score, which harmonizes precision and recall, reached a noteworthy value of 0.88, highlighting the model's balanced proficiency in handling both true positives and true negatives.

The incorporation of the softmax activation function and categorical cross-entropy loss function, along with 32 training epochs, has proven highly effective in refining this model. These results collectively emphasize the model's potential in scene classification tasks, with wide-ranging applications spanning from remote sensing to environmental monitoring and beyond.

## DenseNet-169

### Abstract

Our DenseNet-169 model, meticulously engineered for building and non-building scene classification, has demonstrated excellent performance across a spectrum of vital metrics. Throughout the training process, the model achieved a notably low loss value of 0.2255, signifying its robust predictive capabilities. Additionally, the model showcased impressive accuracy, precision, and recall, all reaching a noteworthy 91.67%. These metrics emphasize the model's commendable proficiency in accurately distinguishing between building and non-building scenes.

The F1 score, a pivotal metric that harmonizes precision and recall, reached an impressive value of 0.92, underscoring the model's capability to effectively handle both true positives and true negatives.

The model's utilization of the softmax activation function and categorical cross-entropy loss function, in conjunction with 32 training epochs, has proven to be a highly effective approach in refining this DenseNet-169 model. These results collectively highlight the model's significant potential in scene classification tasks, with versatile applications spanning remote sensing, environmental monitoring, and beyond.

## DenseNet-121

### Abstract

Our DenseNet-121 model, meticulously designed for building and non-building scene classification, has delivered exceptional performance across a range of critical metrics. Throughout the training process, the model achieved a remarkably low loss value of 0.1827, reflecting its strong predictive capabilities. Furthermore, the model demonstrated outstanding accuracy, precision, and recall, all of which attained an impressive 95.83%. These metrics underscore the model's remarkable proficiency in accurately distinguishing between building and non-building scenes.

The F1 score, a key metric that harmonizes precision and recall, reached an outstanding value of 0.96, illustrating the model's ability to effectively manage both true positives and true negatives.

The employment of the softmax activation function and categorical cross-entropy loss function, alongside 32 training epochs, has proven to be a highly effective strategy in refining this DenseNet-121 model. These results collectively emphasize the model's significant potential in scene classification tasks, with applications spanning a wide array of domains, including remote sensing, environmental monitoring, and beyond.

## MobileNetV2

### Abstract

Our MobileNetV2_1 model, purposefully designed for building and non-building scene classification, has showcased exceptional performance across a spectrum of crucial metrics. Throughout the training phase, the model achieved a remarkably low loss value of 0.1338, reflecting its robust predictive capabilities. Moreover, the model demonstrated an outstanding accuracy, precision, and recall, all registering an impressive 97.50%. These metrics underscore the model's remarkable proficiency in accurately distinguishing between building and non-building scenes.

The F1 score, a pivotal metric that harmonizes precision and recall, reached an outstanding value of 0.97, signifying the model's ability to effectively manage both true positives and true negatives.

The utilization of the softmax activation function and categorical cross-entropy loss function, along with 32 training epochs, has proven to be a highly effective strategy in refining this MobileNetV2_1 model. These results collectively emphasize the model's significant potential in scene classification tasks, with wide-ranging applications spanning remote sensing, environmental monitoring, and beyond.

## Objective

The objective of this project is to develop a deep learning model for classifying high-resolution satellite images into "building" and "non-building" categories using various advanced architectures. The model aims to achieve high accuracy in identifying structural damage in satellite imagery, particularly in post-earthquake scenarios. Through this project, we aim to demonstrate the effectiveness of deep learning in image classification tasks and its application in real-world disaster response scenarios.
